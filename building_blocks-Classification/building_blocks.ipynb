{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corresponding_classes = {'001':'废品', '002' : '次等品' ,'003':'良品'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "from PIL import Image\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python.ops import random_ops,control_flow_ops\n",
    "from tensorflow.python.keras.initializers import he_normal\n",
    "import cv2\n",
    "import math\n",
    "import sys\n",
    "add_dir = os.path.abspath(\"/opt/DahuaTech/MVViewer/share/Python\")\n",
    "sys.path.append(add_dir)\n",
    "from capture import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_boolean('random_flip', True, \"Whether to random flip\")\n",
    "tf.app.flags.DEFINE_boolean('random_brightness', True, \"whether to adjust brightness\")\n",
    "tf.app.flags.DEFINE_boolean('random_contrast', True, \"whether to random constrast\")\n",
    "\n",
    "tf.app.flags.DEFINE_integer('charset_size', 3, \"Choose the first `charset_size` character to conduct our experiment.\")\n",
    "tf.app.flags.DEFINE_integer('image_size', 416, \"Needs to provide same value as in training.\")\n",
    "tf.app.flags.DEFINE_boolean('gray', True, \"whether to change the rbg to gray\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 100000, 'the max training steps ')\n",
    "tf.app.flags.DEFINE_integer('eval_steps', 50, \"the step num to eval\")\n",
    "tf.app.flags.DEFINE_integer('save_steps', 2000, \"the steps to save\")\n",
    "\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', '/media/xinje/New Volume/building_blocks/checkpoint/', 'the checkpoint dir')\n",
    "tf.app.flags.DEFINE_string('train_data_dir', './data2/train/', 'the train dataset dir')\n",
    "tf.app.flags.DEFINE_string('test_data_dir', './data2/test/', 'the test dataset dir')\n",
    "tf.app.flags.DEFINE_string('log_dir', './log', 'the logging dir')\n",
    "\n",
    "tf.app.flags.DEFINE_boolean('restore', False, 'whether to restore from checkpoint')\n",
    "tf.app.flags.DEFINE_integer('epoch', 1, 'Number of epoches')\n",
    "tf.app.flags.DEFINE_integer('batch_size', 16, 'Validation batch size')\n",
    "tf.app.flags.DEFINE_string('mode', 'train', 'Running mode. One of {\"train\", \"valid\", \"test\"}')\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image):\n",
    "\n",
    "    rand_num = random.random()*2-1\n",
    "    if(rand_num <(-1/3)):\n",
    "        return cv2.flip(image, -1)\n",
    "    elif(rand_num>(-1/3) and rand_num < (1/3)):\n",
    "        return cv2.flip(image, 0)\n",
    "    elif(rand_num>(1/3)):\n",
    "        return cv2.flip(image, 1)\n",
    "    else:\n",
    "        return cv2.flip(image, rand_num)\n",
    "    \n",
    "def random_crop(image):\n",
    "    rate = (random.random()+1)*0.1*0.5 #random crop 10% to 20%\n",
    "    cropImg = image[int(image.shape[0]*rate):int(image.shape[0]*(1-rate)),int(image.shape[1]*rate):int(image.shape[1]*(1-rate))]\n",
    "    return cropImg\n",
    "    \n",
    "def random_rotate_image(image):\n",
    "    #random rotate\n",
    "    (h,w) = image.shape[:2]\n",
    "    center = (w//2,h//2)\n",
    "    M = cv2.getRotationMatrix2D(center,random.random()*360,1.0)\n",
    "    image = cv2.warpAffine(image,M,(w,h),borderMode = cv2.BORDER_REPLICATE)\n",
    "    return image\n",
    "\n",
    "def random_distort_image(image, hue=18, saturation=1.5, exposure=1.5):\n",
    "    def _rand_scale(scale):\n",
    "        scale = np.random.uniform(1, scale)\n",
    "        return scale if (np.random.randint(2) == 0) else 1. / scale\n",
    "\n",
    "    # determine scale factors\n",
    "    dhue = np.random.uniform(-hue, hue)\n",
    "    dsat = _rand_scale(saturation)\n",
    "    dexp = _rand_scale(exposure)\n",
    "    # convert RGB space to HSV space\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype('float')\n",
    "    # change satuation and exposure\n",
    "    image[:, :, 1] *= dsat\n",
    "    image[:, :, 2] *= dexp\n",
    "    # change hue\n",
    "    image[:, :, 0] += dhue\n",
    "    image[:, :, 0] -= (image[:, :, 0] > 180) * 180\n",
    "    image[:, :, 0] += (image[:, :, 0] < 0) * 180\n",
    "    \n",
    "    # avoid overflow when astype('uint8')\n",
    "    image[...] = np.clip(image[...], 0, 255)\n",
    "    # convert back to RGB from HSV\n",
    "    return cv2.cvtColor(image.astype('uint8'), cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def data_augmentation(image):\n",
    "    image = random_crop(image)\n",
    "    image = random_flip(image)\n",
    "    image = random_rotate_image(image)\n",
    "    image = random_distort_image(image, hue=18, saturation=1.5, exposure=1.5)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list(data_dir):\n",
    "    img_list = []\n",
    "    #get the file name from dir 0\n",
    "    for _,file_path,files in os.walk(data_dir+str(0)):\n",
    "        for file in files:\n",
    "            img_list.append([data_dir+str(0)+'/'+file,0])\n",
    "    #get the file name from dir 1        \n",
    "    for _,file_path,files in os.walk(data_dir+str(1)):\n",
    "        for file in files:\n",
    "            img_list.append([data_dir+str(1)+'/'+file,1])\n",
    "\n",
    "    random.shuffle(img_list)\n",
    "    return img_list\n",
    "\n",
    "def read_data(img_list,batch_size,aug):\n",
    "    num_batch = len(img_list)/batch_size\n",
    "    count=0\n",
    "    while(True):\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        for i in range(batch_size):\n",
    "            temp_index = i+count*batch_size\n",
    "            temp_index %=len(img_list) \n",
    "            image = cv2.imread(img_list[temp_index][0])\n",
    "            if aug:\n",
    "                image = data_augmentation(image)\n",
    "            image = image[:,:,::-1]\n",
    "            image = image.astype(np.float32)\n",
    "            image = cv2.resize(image,(FLAGS.image_size,FLAGS.image_size))\n",
    "            image = image/255\n",
    "            x_data.append(image)\n",
    "            y_data.append(img_list[temp_index][1])\n",
    "        count+=1\n",
    "        x_data = np.array(x_data)\n",
    "        yield x_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataIterator:\n",
    "#     def __init__(self, data_dir):\n",
    "#         # Set FLAGS.charset_size to a small value if available computation power is limited.\n",
    "#         truncate_path = data_dir  +('%d' % FLAGS.charset_size)\n",
    "#         #print(truncate_path)\n",
    "#         self.image_names = []\n",
    "#         for root, sub_folder, file_list in os.walk(data_dir):\n",
    "#             print(root)\n",
    "#             if root < truncate_path:\n",
    "#                 self.image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "#         random.shuffle(self.image_names)\n",
    "#         self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\n",
    "#         #print(self.image_names)\n",
    "#         #print(len(self.image_names))\n",
    "\n",
    "#     @property\n",
    "#     def size(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def data_augmentation(images):\n",
    "#         if FLAGS.random_flip:\n",
    "#             images = tf.image.random_flip_up_down(images)\n",
    "#             images = tf.image.random_flip_left_right(images)\n",
    "#             images = tf.image.random_hue(images,max_delta=0.3)\n",
    "#             images = tf.image.random_contrast(images, 0.8, 1.2)\n",
    "#             images = tf.image.random_brightness(images, max_delta=0.3)\n",
    "#             degree_angle = random.random()*360\n",
    "#             angles = degree_angle *math.pi/180\n",
    "#             images = tf.contrib.image.rotate(images,angles=angles,interpolation='BILINEAR')\n",
    "#         return images\n",
    "\n",
    "#     def input_pipeline(self, batch_size, num_epochs=None, aug=True):\n",
    "#         images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\n",
    "#         labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\n",
    "#         input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\n",
    "\n",
    "#         labels = input_queue[1]\n",
    "#         #print(input_queue)\n",
    "#         images_content = tf.read_file(input_queue[0])\n",
    "#         images = tf.image.convert_image_dtype(tf.image.decode_bmp(images_content, channels=3), tf.float32)\n",
    "#         if aug:\n",
    "#             images = self.data_augmentation(images)\n",
    "#         new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\n",
    "#         images = tf.image.resize_images(images, new_size)\n",
    "#         image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batch_size, capacity=5000,\n",
    "#                                                           min_after_dequeue=500)\n",
    "#         return image_batch, label_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataIterator2:\n",
    "#     def __init__(self, data_dir):\n",
    "#         truncate_path = data_dir  +('%d' % FLAGS.charset_size)\n",
    "#         self.image_names = []\n",
    "#         for root, sub_folder, file_list in os.walk(data_dir):\n",
    "#             print(root)\n",
    "#             if root < truncate_path:\n",
    "#                 self.image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "#         random.shuffle(self.image_names)\n",
    "#         self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\n",
    "\n",
    "#     @property\n",
    "#     def size(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def data_augmentation(images):\n",
    "#         if FLAGS.random_flip_up_down:\n",
    "#             images = tf.image.random_flip_up_down(images)\n",
    "#         if FLAGS.random_brightness:\n",
    "#             images = tf.image.random_brightness(images, max_delta=0.3)\n",
    "#         if FLAGS.random_contrast:\n",
    "#             images = tf.image.random_contrast(images, 0.8, 1.2)\n",
    "#         return images\n",
    "\n",
    "#     def input_pipeline(self, batch_size, num_epochs=None, aug=True):\n",
    "#         images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\n",
    "#         labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\n",
    "#         input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\n",
    "\n",
    "#         labels = input_queue[1]\n",
    "#         #print(input_queue)\n",
    "#         images_content = tf.read_file(input_queue[0])\n",
    "#         images_names = input_queue[0]\n",
    "#         images = tf.image.convert_image_dtype(tf.image.decode_bmp(images_content, channels=3), tf.float32)\n",
    "#         if aug:\n",
    "#             images = self.data_augmentation(images)\n",
    "#         new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\n",
    "#         images = tf.image.resize_images(images, new_size)\n",
    "#         image_batch, label_batch,file_name = tf.train.batch([images, labels,images_names], batch_size=batch_size, capacity=5000)\n",
    "#         #file_name = tf.as_string(file_name)\n",
    "#         return image_batch, label_batch,file_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataIterator3:\n",
    "#     def __init__(self, data_dir):\n",
    "#         truncate_path = data_dir  +('%d' % FLAGS.charset_size)\n",
    "#         self.image_names = []\n",
    "#         for root, sub_folder, file_list in os.walk(data_dir):\n",
    "#             print(root)\n",
    "#             if root < truncate_path:\n",
    "#                 self.image_names += [os.path.join(root, file_path) for file_path in file_list]\n",
    "#         random.shuffle(self.image_names)\n",
    "#         self.labels = [int(file_name[len(data_dir):].split(os.sep)[0]) for file_name in self.image_names]\n",
    "\n",
    "#     @property\n",
    "#     def size(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def data_augmentation(images):\n",
    "#         if FLAGS.random_flip_up_down:\n",
    "#             images = tf.image.random_flip_up_down(images)\n",
    "#         if FLAGS.random_brightness:\n",
    "#             images = tf.image.random_brightness(images, max_delta=0.3)\n",
    "#         if FLAGS.random_contrast:\n",
    "#             images = tf.image.random_contrast(images, 0.8, 1.2)\n",
    "#         return images\n",
    "\n",
    "#     def input_pipeline(self, batch_size, num_epochs=None, aug=True):\n",
    "#         images_tensor = tf.convert_to_tensor(self.image_names, dtype=tf.string)\n",
    "#         labels_tensor = tf.convert_to_tensor(self.labels, dtype=tf.int64)\n",
    "#         input_queue = tf.train.slice_input_producer([images_tensor, labels_tensor], num_epochs=num_epochs)\n",
    "\n",
    "#         labels = input_queue[1]\n",
    "#         #print(input_queue)\n",
    "#         images_content = tf.read_file(input_queue[0])\n",
    "#         images_names = input_queue[0]\n",
    "#         images = tf.image.convert_image_dtype(tf.image.decode_bmp(images_content, channels=3), tf.float32)\n",
    "# #         if aug:\n",
    "# #             images = self.data_augmentation(images)\n",
    "#         new_size = tf.constant([FLAGS.image_size, FLAGS.image_size], dtype=tf.int32)\n",
    "#         images = tf.image.resize_images(images, new_size)\n",
    "#         image_batch, label_batch = tf.train.batch([images, labels], batch_size=batch_size, capacity=5000)\n",
    "#         #file_name = tf.as_string(file_name)\n",
    "#         return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(prev_layer, num_units, is_training):\n",
    "    layer = tf.layers.dense(prev_layer, num_units, use_bias=True, activation=None)\n",
    "    layer = tf.layers.batch_normalization(layer, training=is_training)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_conv(prev_layer, layer_depth, is_training):\n",
    "    conv_layer1 = tf.layers.conv2d(prev_layer, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer1_bn = tf.layers.batch_normalization(conv_layer1, training=is_training)\n",
    "    conv_layer1_out = tf.nn.relu(conv_layer1_bn)\n",
    "\n",
    "    pool_layer1 = tf.layers.max_pooling2d(conv_layer1_out,[2,2],strides=2)\n",
    "    return pool_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_2conv(prev_layer, layer_depth, is_training):\n",
    "    conv_layer1 = tf.layers.conv2d(prev_layer, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer1_bn = tf.layers.batch_normalization(conv_layer1, training=is_training)\n",
    "    conv_layer1_out = tf.nn.relu(conv_layer1_bn)\n",
    "    \n",
    "    conv_layer2 = tf.layers.conv2d(conv_layer1_out, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer2_bn = tf.layers.batch_normalization(conv_layer2, training=is_training)\n",
    "    conv_layer2_out = tf.nn.relu(conv_layer2_bn)\n",
    "\n",
    "    pool_layer2 = tf.layers.max_pooling2d(conv_layer2_out,[2,2],strides=2)\n",
    "    return pool_layer2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_3conv(prev_layer, layer_depth, is_training):\n",
    "    conv_layer1 = tf.layers.conv2d(prev_layer, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer1_bn = tf.layers.batch_normalization(conv_layer1, training=is_training)\n",
    "    conv_layer1_out = tf.nn.relu(conv_layer1_bn)\n",
    "    \n",
    "    conv_layer2 = tf.layers.conv2d(conv_layer1_out, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer2_bn = tf.layers.batch_normalization(conv_layer2, training=is_training)\n",
    "    conv_layer2_out = tf.nn.relu(conv_layer2_bn)\n",
    "    \n",
    "    conv_layer3 = tf.layers.conv2d(conv_layer2_out, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer3_bn = tf.layers.batch_normalization(conv_layer3, training=is_training)\n",
    "    conv_layer3_out = tf.nn.relu(conv_layer3_bn)\n",
    "    pool_layer3 = tf.layers.max_pooling2d(conv_layer3_out,[2,2],strides=2)\n",
    "    return pool_layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_4conv(prev_layer, layer_depth, is_training):\n",
    "    conv_layer1 = tf.layers.conv2d(prev_layer, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer1_bn = tf.layers.batch_normalization(conv_layer1, training=is_training)\n",
    "    conv_layer1_out = tf.nn.relu(conv_layer1_bn)\n",
    "    \n",
    "    conv_layer2 = tf.layers.conv2d(conv_layer1_out, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer2_bn = tf.layers.batch_normalization(conv_layer2, training=is_training)\n",
    "    conv_layer2_out = tf.nn.relu(conv_layer2_bn)\n",
    "    \n",
    "    conv_layer3 = tf.layers.conv2d(conv_layer2_out, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer3_bn = tf.layers.batch_normalization(conv_layer3, training=is_training)\n",
    "    conv_layer3_out = tf.nn.relu(conv_layer3_bn)\n",
    "    \n",
    "    conv_layer4 = tf.layers.conv2d(conv_layer3_out, layer_depth, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer4_bn = tf.layers.batch_normalization(conv_layer4, training=is_training)\n",
    "    conv_layer4_out = tf.nn.relu(conv_layer4_bn)\n",
    "    pool_layer4 = tf.layers.max_pooling2d(conv_layer4_out,[2,2],strides=2)\n",
    "    return pool_layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(layer,layer_depth,is_training):\n",
    "    depth1,depth2,depth3 = layer_depth\n",
    "    shortcut = layer\n",
    "    conv_layer1 = tf.layers.conv2d(layer, depth1, [1,1], 2, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer1_bn = tf.layers.batch_normalization(conv_layer1, training=is_training)\n",
    "    conv_layer1_out = tf.nn.relu(conv_layer1_bn)\n",
    "    \n",
    "    conv_layer2 = tf.layers.conv2d(conv_layer1_out, depth2, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer2_bn = tf.layers.batch_normalization(conv_layer2, training=is_training)\n",
    "    conv_layer2_out = tf.nn.relu(conv_layer2_bn)\n",
    "    \n",
    "    conv_layer3 = tf.layers.conv2d(conv_layer2_out, depth3, [1,1], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer3_bn = tf.layers.batch_normalization(conv_layer3, training=is_training)\n",
    "    \n",
    "    conv_temp = tf.layers.conv2d(shortcut,depth3,[1,1],2,'same')\n",
    "    conv_temp = tf.layers.batch_normalization(conv_temp,training=is_training)\n",
    "    conv_add = conv_temp+conv_layer3_bn\n",
    "    conv_layer3_out = tf.nn.relu(conv_add)\n",
    "#     pool_layer3 = tf.layers.max_pooling2d(conv_layer3_out,[2,2],strides=2)\n",
    "    return conv_layer3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(layer,layer_depth,is_training):\n",
    "    depth1,depth2,depth3 = layer_depth\n",
    "    shortcut = layer\n",
    "    conv_layer1 = tf.layers.conv2d(layer, depth1, [1,1], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer1_bn = tf.layers.batch_normalization(conv_layer1, training=is_training)\n",
    "    conv_layer1_out = tf.nn.relu(conv_layer1_bn)\n",
    "    \n",
    "    conv_layer2 = tf.layers.conv2d(conv_layer1_out, depth2, [3,3], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer2_bn = tf.layers.batch_normalization(conv_layer2, training=is_training)\n",
    "    conv_layer2_out = tf.nn.relu(conv_layer2_bn)\n",
    "    \n",
    "    conv_layer3 = tf.layers.conv2d(conv_layer2_out, depth3, [1,1], 1, 'same', use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    conv_layer3_bn = tf.layers.batch_normalization(conv_layer3, training=is_training)\n",
    "    \n",
    "#     conv_temp = tf.layers.conv2d(shortcut,depth3,[1,1],1,'same')\n",
    "    conv_add = shortcut+conv_layer3_bn\n",
    "    conv_layer3_out = tf.nn.relu(conv_add)\n",
    "\n",
    "    return conv_layer3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def capture_image():\n",
    "#     cameraCnt, cameraList = enumCameras()\n",
    "#     camera = cameraList[0]\n",
    "#     nRet = openCamera(camera)\n",
    "\n",
    "#     streamSourceInfo = GENICAM_StreamSourceInfo()\n",
    "#     streamSourceInfo.channelId = 0\n",
    "#     streamSourceInfo.pCamera = pointer(camera)\n",
    "\n",
    "#     streamSource = pointer(GENICAM_StreamSource())\n",
    "#     nRet = GENICAM_createStreamSource(pointer(streamSourceInfo), byref(streamSource))\n",
    "#     nRet = setSoftTriggerConf(camera)\n",
    "\n",
    "#     nRet = streamSource.contents.startGrabbing(streamSource, c_ulonglong(0), c_int(GENICAM_EGrabStrategy.grabStrartegySequential))\n",
    "#     time.sleep(1)\n",
    "#     nRet = grabOne(camera)  \n",
    "#     if( nRet != 0 ):\n",
    "#         print(\"grabOne fail!\")\n",
    "#         # 释放相关资源\n",
    "#         streamSource.contents.release(streamSource)        \n",
    "#     else:\n",
    "#         print(\"trigger time: \" + str(datetime.datetime.now()))\n",
    "\n",
    "#     frame = pointer(GENICAM_Frame())\n",
    "#     nRet = streamSource.contents.getFrame(streamSource, byref(frame), c_uint(1000))\n",
    "#     if ( nRet != 0 ):\n",
    "#         print(\"SoftTrigger getFrame fail! timeOut [1000]ms\")\n",
    "#         # 释放相关资源\n",
    "#         streamSource.contents.release(streamSource)   \n",
    "#     else:\n",
    "#         print(\"SoftTrigger getFrame success BlockId = \" + str(frame.contents.getBlockId(frame))) \n",
    "#         print(\"get frame time: \" + str(datetime.datetime.now()))   \n",
    "\n",
    "#     nRet = frame.contents.valid(frame)\n",
    "#     if ( nRet != 0 ):\n",
    "#         print(\"frame is invalid!\")\n",
    "#         # 释放驱动图像缓存资源\n",
    "#         frame.contents.release(frame)\n",
    "#         # 释放相关资源\n",
    "#         streamSource.contents.release(streamSource)\n",
    "\n",
    "\n",
    "#     imageSize = frame.contents.getImageSize(frame)\n",
    "#     buffAddr = frame.contents.getImage(frame)\n",
    "#     frameBuff = c_buffer(b'\\0', imageSize)\n",
    "#     memmove(frameBuff, c_char_p(buffAddr), imageSize)\n",
    "\n",
    "#     convertParams = IMGCNV_SOpenParam()\n",
    "#     convertParams.dataSize = imageSize\n",
    "#     convertParams.height = frame.contents.getImageHeight(frame)\n",
    "#     convertParams.width = frame.contents.getImageWidth(frame)\n",
    "#     convertParams.paddingX = frame.contents.getImagePaddingX(frame)\n",
    "#     convertParams.paddingY = frame.contents.getImagePaddingY(frame)\n",
    "#     convertParams.pixelForamt = frame.contents.getImagePixelFormat(frame)\n",
    "#     frame.contents.release(frame)\n",
    "\n",
    "#     # 保存bmp图片  \n",
    "#     bmpInfoHeader = BITMAPINFOHEADER() \n",
    "#     bmpFileHeader = BITMAPFILEHEADER()\n",
    "\n",
    "#     uRgbQuadLen = 0\n",
    "#     rgbQuad = (RGBQUAD * 256)() # 调色板信息\n",
    "#     rgbBuff = c_buffer(b'\\0', convertParams.height * convertParams.width * 3)\n",
    "\n",
    "#     # 如果图像格式是 Mono8 不需要转码 \n",
    "#     if convertParams.pixelForamt == EPixelType.gvspPixelMono8:\n",
    "#         # 初始化调色板rgbQuad 实际应用中 rgbQuad 只需初始化一次\n",
    "#         for i in range(0, 256):\n",
    "#             rgbQuad[i].rgbBlue = rgbQuad[i].rgbGreen = rgbQuad[i].rgbRed = i;\n",
    "\n",
    "#         uRgbQuadLen = sizeof(RGBQUAD) * 256    \n",
    "#         bmpFileHeader.bfSize = sizeof(bmpFileHeader) + sizeof(bmpInfoHeader) + uRgbQuadLen + convertParams.dataSize\n",
    "#         bmpInfoHeader.biBitCount = 8\n",
    "#     else:\n",
    "#         # 转码 => BGR24\n",
    "#         rgbSize = c_int()\n",
    "#         nRet = IMGCNV_ConvertToBGR24(cast(frameBuff, c_void_p), byref(convertParams), \\\n",
    "#                                      cast(rgbBuff, c_void_p), byref(rgbSize))\n",
    "\n",
    "#         if ( nRet != 0 ):\n",
    "#             print(\"image convert fail! errorCode = \" + str(nRet))\n",
    "#             # 释放相关资源\n",
    "#             streamSource.contents.release(streamSource) \n",
    "\n",
    "#         bmpFileHeader.bfSize = sizeof(bmpFileHeader) + sizeof(bmpInfoHeader) + rgbSize.value\n",
    "#         bmpInfoHeader.biBitCount = 24   \n",
    "\n",
    "#     if convertParams.pixelForamt == EPixelType.gvspPixelMono8:\n",
    "\n",
    "#         image_information = frameBuff\n",
    "#     else: \n",
    "#         image_information = rgbBuff\n",
    "#     nRet = streamSource.contents.stopGrabbing(streamSource)\n",
    "#     nRet = closeCamera(camera)\n",
    "#     streamSource.contents.release(streamSource)\n",
    "#     return image_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_50(layer):\n",
    "    #stage1\n",
    "    X = tf.layers.conv2d(layer,64,[7,7],2,'valid',use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    X = tf.layers.batch_normalization(X,training=is_training)\n",
    "    X = tf.nn.relu(X)\n",
    "    X = tf.layers.max_pooling2d(X,[3,3],strides=2)\n",
    "#stage2    \n",
    "    X = convolutional_block(X,[64,64,256],is_training)\n",
    "    X = identity_block(X,[64,64,256],is_training)\n",
    "    X = identity_block(X,[64,64,256],is_training)\n",
    "    \n",
    "#stage3\n",
    "    X = convolutional_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "\n",
    "#stage4\n",
    "    X = convolutional_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "\n",
    "#stage5\n",
    "    X = convolutional_block(X,[512,512,2048],is_training)\n",
    "    X = identity_block(X,[512,512,2048],is_training)\n",
    "    X = identity_block(X,[512,512,2048],is_training)\n",
    "#average_pooling\n",
    "    X = tf.layers.average_pooling2d(X,[2,2],strides=2)\n",
    "# Flatten the output from the convolutional layers\n",
    "    orig_shape = X.get_shape().as_list()\n",
    "    layer = tf.reshape(X, shape=[-1, orig_shape[1]*orig_shape[2]*orig_shape[3]])\n",
    "    layer_drop = tf.nn.dropout(layer,keep_prob)\n",
    "    layer2 = fully_connected(layer_drop, 1000, is_training)\n",
    "    layer_drop2 = tf.nn.dropout(layer2,keep_prob)\n",
    "    logits = tf.layers.dense(layer_drop2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_101(input_layer):\n",
    "#stage1\n",
    "    X = tf.layers.conv2d(layer,64,[7,7],2,'valid',use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    X = tf.layers.batch_normalization(X,training=is_training)\n",
    "    X = tf.nn.relu(X)\n",
    "    X = tf.layers.max_pooling2d(X,[3,3],strides=2)\n",
    "#stage2    \n",
    "    X = convolutional_block(X,[64,64,256],is_training)\n",
    "    X = identity_block(X,[64,64,256],is_training)\n",
    "    X = identity_block(X,[64,64,256],is_training)\n",
    "    \n",
    "#stage3\n",
    "    X = convolutional_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "#stage4\n",
    "    X = convolutional_block(X,[256,256,1024],is_training)\n",
    "    for i in range(22):\n",
    "        X = identity_block(X,[256,256,1024],is_training)\n",
    "\n",
    "#stage5\n",
    "    X = convolutional_block(X,[512,512,2048],is_training)\n",
    "    X = identity_block(X,[512,512,2048],is_training)\n",
    "    X = identity_block(X,[512,512,2048],is_training)\n",
    "#average_pooling\n",
    "    X = tf.layers.average_pooling2d(X,[2,2],strides=2)\n",
    "# Flatten the output from the convolutional layers\n",
    "    orig_shape = X.get_shape().as_list()\n",
    "    layer = tf.reshape(X, shape=[-1, orig_shape[1]*orig_shape[2]*orig_shape[3]])\n",
    "\n",
    "    layer_drop = tf.nn.dropout(layer,keep_prob)\n",
    "    layer2 = fully_connected(layer_drop, 1000, is_training)\n",
    "    layer_drop2 = tf.nn.dropout(layer2,keep_prob)\n",
    "    logits = tf.layers.dense(layer_drop2, 2)\n",
    "#     l2_loss = tf.losses.get_regularization_loss()\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_16(layer):\n",
    "    conv_layer1 = conv_layer_2conv(layer, 64, is_training)\n",
    "    conv_layer2 = conv_layer_2conv(conv_layer1, 128, is_training)\n",
    "    conv_layer3 = conv_layer_3conv(conv_layer2, 256, is_training)\n",
    "    conv_layer4 = conv_layer_3conv(conv_layer3, 512, is_training)\n",
    "    conv_layer5 = conv_layer_3conv(conv_layer4, 512, is_training)\n",
    "\n",
    "\n",
    "     \n",
    "    # Flatten the output from the convolutional layers\n",
    "    orig_shape = conv_layer5.get_shape().as_list()\n",
    "    layer = tf.reshape(conv_layer5, shape=[-1, orig_shape[1]*orig_shape[2]*orig_shape[3]])\n",
    "    keep_prob = tf.placeholder('float')\n",
    "    layer_drop = tf.nn.dropout(layer,keep_prob)\n",
    "    layer2 = fully_connected(layer_drop, 4096, is_training)\n",
    "    layer_drop2 = tf.nn.dropout(layer2,keep_prob)\n",
    "    layer3 = fully_connected(layer_drop2, 4096, is_training)\n",
    "    layer_drop3 = tf.nn.dropout(layer3,keep_prob)\n",
    "    logits = tf.layers.dense(layer_drop3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch(num_batches, batch_size, learning_rate):\n",
    "\n",
    "    inputs = tf.placeholder(tf.float32, [None, FLAGS.image_size, FLAGS.image_size, 3])\n",
    "    labels = tf.placeholder(tf.int64, [None])\n",
    "    keep_prob = tf.placeholder('float')\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    layer = inputs \n",
    "\n",
    "\n",
    "    #stage1\n",
    "    X = tf.layers.conv2d(layer,64,[7,7],2,'valid',use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    X = tf.layers.batch_normalization(X,training=is_training)\n",
    "    X = tf.nn.relu(X)\n",
    "    X = tf.layers.max_pooling2d(X,[3,3],strides=2)\n",
    "#stage2    \n",
    "    X = convolutional_block(X,[64,64,256],is_training)\n",
    "    X = identity_block(X,[64,64,256],is_training)\n",
    "    X = identity_block(X,[64,64,256],is_training)\n",
    "    \n",
    "#stage3\n",
    "    X = convolutional_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "\n",
    "#stage4\n",
    "    X = convolutional_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "\n",
    "#stage5\n",
    "    X = convolutional_block(X,[512,512,2048],is_training)\n",
    "    X = identity_block(X,[512,512,2048],is_training)\n",
    "    X = identity_block(X,[512,512,2048],is_training)\n",
    "#average_pooling\n",
    "    X = tf.layers.average_pooling2d(X,[2,2],strides=2)\n",
    "# Flatten the output from the convolutional layers\n",
    "    orig_shape = X.get_shape().as_list()\n",
    "    layer = tf.reshape(X, shape=[-1, orig_shape[1]*orig_shape[2]*orig_shape[3]])\n",
    "    layer_drop = tf.nn.dropout(layer,keep_prob)\n",
    "    layer2 = fully_connected(layer_drop, 1000, is_training)\n",
    "    layer_drop2 = tf.nn.dropout(layer2,keep_prob)\n",
    "    logits = tf.layers.dense(layer_drop2, 2)\n",
    "\n",
    "\n",
    "    l2_loss = tf.losses.get_regularization_loss()\n",
    "    model_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    model_loss = model_loss+l2_loss\n",
    "    # Tell TensorFlow to update the population statistics while training\n",
    "    global_step = tf.get_variable(\"step\", [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "    rate = tf.train.exponential_decay(learning_rate, global_step, decay_steps=1000, decay_rate=0.97, staircase=True)\n",
    "#     rate = learning_rate\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        train_opt = tf.train.AdamOptimizer(rate).minimize(model_loss,global_step=global_step)\n",
    "\n",
    "    # Create operations to test accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), labels), tf.float32))\n",
    "    tf.summary.scalar('loss',model_loss)\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "    tf.summary.scalar('learning_rate',rate)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    # Train and test the network\n",
    "    \n",
    "    print('Strart training:')\n",
    "    with tf.Session() as sess:\n",
    "        train_list = create_file_list('./data2/train/')\n",
    "        test_list = create_file_list('./data2/test/')\n",
    "        train_feeder = read_data(train_list,batch_size,True)\n",
    "        test_feeder = read_data(test_list,batch_size,False)\n",
    "        test_feeder_final = read_data(test_list,1,False)\n",
    "#         train_feeder = DataIterator(data_dir='./data2/train/')\n",
    "#         test_feeder = DataIterator3(data_dir='./data2/test/')\n",
    "#         train_images, train_labels = train_feeder.input_pipeline(batch_size)\n",
    "#         test_images, test_labels = test_feeder.input_pipeline(batch_size)\n",
    "#         test_images_1, test_labels_1 = test_feeder.input_pipeline(1)\n",
    "        train_writer = tf.summary.FileWriter(FLAGS.log_dir+'/train',sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(FLAGS.log_dir+'/test')\n",
    "        saver = tf.train.Saver(max_to_keep =100)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "        if ckpt:\n",
    "            saver.restore(sess,ckpt)\n",
    "            print('restore from the checkpoint {0}'.format(ckpt))\n",
    "            global_step = global_step+int(ckpt.split('-')[-1])\n",
    "            \n",
    "        time.sleep(1)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        try:\n",
    "            #using progress bar\n",
    "            for batch_i in range(int(num_batches/50)):\n",
    "                # train this batch\n",
    "                temp_bar = tqdm([i+1 for i in range(50)])\n",
    "                for i in temp_bar:\n",
    "                    [train_images_batch, train_labels_batch] = next(train_feeder)\n",
    "                    _,loss,acc = sess.run([train_opt,model_loss, accuracy], feed_dict={inputs: train_images_batch, labels: train_labels_batch, is_training: True,keep_prob:0.5})\n",
    "                    # Periodically check the validation or training loss and accuracy\n",
    "                    temp_bar.set_description('Batch: {:>2}: Training loss: {:>3.5f}, Training accuracy: {:>3.5f}'.format(batch_i*50+i, loss, acc))\n",
    "                    if (batch_i*50+i)%200 == 0:\n",
    "    #                     test_images_batch, test_labels_batch = sess.run([test_images, test_labels])\n",
    "                        [test_images_batch, test_labels_batch] =next(test_feeder)\n",
    "                        loss, acc,summary_op_test = sess.run([model_loss, accuracy,merged_summary_op], feed_dict={inputs: test_images_batch,\n",
    "                                                                      labels: test_labels_batch,\n",
    "                                                                      is_training: False,keep_prob:1.0})\n",
    "                        test_writer.add_summary(summary_op_test, batch_i*50+i)\n",
    "                        saver.save(sess,os.path.join(FLAGS.checkpoint_dir,'CH-reco'),global_step = batch_i*50+i)\n",
    "                        temp_bar.set_description(\n",
    "                            'Batch: {:>2}: Validation loss: {:>3.5f}, Validation accuracy: {:>3.5f}'.format(batch_i*50+i, loss, acc))\n",
    "                    elif (batch_i*50+i)%50 == 0:\n",
    "                        loss, acc,summary_op_train = sess.run([model_loss, accuracy,merged_summary_op], feed_dict={inputs: train_images_batch, labels: train_labels_batch, is_training: False,keep_prob:1.0})\n",
    "                        train_writer.add_summary(summary_op_train, batch_i*50+i)\n",
    "#                         print('Batch: {:>2}: Training loss: {:>3.5f}, Training accuracy: {:>3.5f}'.format(batch_i, loss, acc))\n",
    "                    elif (batch_i*50+i) ==(num_batches-1):\n",
    "                        accuracy_temp=0.0\n",
    "                        for batch_j in range(test_feeder.size):\n",
    "                            [test_images_batch_1, test_labels_batch_1] = next(test_feeder_final)\n",
    "    #                         test_images_batch_1, test_labels_batch_1 = sess.run([test_images_1, test_labels_1])\n",
    "                            [lg,acc] = sess.run([logits,accuracy], feed_dict={inputs: test_images_batch_1,labels: test_labels_batch_1,is_training: False,keep_prob:1.0})\n",
    "                            accuracy_temp +=acc\n",
    "                            print(lg)\n",
    "                            print('Current test accuracy:{:>3.5f}'.format(acc))\n",
    "                        accuracy_final = accuracy_temp/test_feeder.size\n",
    "                        print('Final test accuracy: {:>3.5f} in {:>1} samples'.format(accuracy_final,test_feeder.size))\n",
    "                    \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('error')\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strart training:\n",
      "INFO:tensorflow:Restoring parameters from /media/xinje/New Volume/building_blocks/checkpoint/CH-reco-49600\n",
      "restore from the checkpoint /media/xinje/New Volume/building_blocks/checkpoint/CH-reco-49600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 50: Training loss: 0.31408, Training accuracy: 0.96875: 100%|██████████| 50/50 [01:07<00:00,  1.36s/it]\n",
      "Batch: 100: Training loss: 0.28817, Training accuracy: 1.00000: 100%|██████████| 50/50 [01:01<00:00,  1.23s/it]\n",
      "Batch: 150: Training loss: 0.28735, Training accuracy: 1.00000: 100%|██████████| 50/50 [01:01<00:00,  1.23s/it]\n",
      "Batch: 200: Validation loss: 0.63089, Validation accuracy: 0.93750: 100%|██████████| 50/50 [01:04<00:00,  1.29s/it]\n",
      "Batch: 250: Training loss: 0.29401, Training accuracy: 1.00000: 100%|██████████| 50/50 [01:01<00:00,  1.22s/it]\n",
      "Batch: 300: Training loss: 0.29345, Training accuracy: 1.00000: 100%|██████████| 50/50 [01:00<00:00,  1.21s/it]\n",
      "Batch: 350: Training loss: 0.33578, Training accuracy: 0.96875: 100%|██████████| 50/50 [01:00<00:00,  1.22s/it]\n",
      "Batch: 400: Validation loss: 0.79781, Validation accuracy: 0.90625: 100%|██████████| 50/50 [01:03<00:00,  1.27s/it]\n",
      "Batch: 450: Training loss: 0.36924, Training accuracy: 0.96875: 100%|██████████| 50/50 [01:01<00:00,  1.22s/it]\n",
      "Batch: 460: Training loss: 0.28722, Training accuracy: 1.00000:  20%|██        | 10/50 [00:12<00:49,  1.23s/it]"
     ]
    }
   ],
   "source": [
    "num_batches = 50000 # 迭代次数\n",
    "batch_size = 32  # 批处理数量\n",
    "learning_rate = 1e-6  # 学习率\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    train_ch(num_batches, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inference():\n",
    "\n",
    "    inputs = tf.placeholder(tf.float32, [None, FLAGS.image_size, FLAGS.image_size, 3])\n",
    "    labels = tf.placeholder(tf.int64, [None])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    keep_prob = tf.placeholder('float')\n",
    "    layer = inputs \n",
    "#stage1\n",
    "    X = tf.layers.conv2d(layer,64,[7,7],2,'valid',use_bias=True,kernel_initializer=he_normal(seed=0.01),activation=None,kernel_regularizer=tf.contrib.layers.l2_regularizer(0.01))\n",
    "    X = tf.layers.batch_normalization(X,training=is_training)\n",
    "    X = tf.nn.relu(X)\n",
    "    X = tf.layers.max_pooling2d(X,[3,3],strides=2)\n",
    "#stage2    \n",
    "    X = convolutional_block(X,[64,64,256],is_training)\n",
    "    X = identity_block(X,[64,64,256],is_training)\n",
    "    X = identity_block(X,[64,64,256],is_training)\n",
    "    \n",
    "#stage3\n",
    "    X = convolutional_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "    X = identity_block(X,[128,128,512],is_training)\n",
    "\n",
    "#stage4\n",
    "    X = convolutional_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "    X = identity_block(X,[256,256,1024],is_training)\n",
    "\n",
    "#stage5\n",
    "    X = convolutional_block(X,[512,512,2048],is_training)\n",
    "    X = identity_block(X,[512,512,2048],is_training)\n",
    "    X = identity_block(X,[512,512,2048],is_training)\n",
    "#average_pooling\n",
    "    X = tf.layers.average_pooling2d(X,[2,2],strides=2)\n",
    "# Flatten the output from the convolutional layers\n",
    "    orig_shape = X.get_shape().as_list()\n",
    "    layer = tf.reshape(X, shape=[-1, orig_shape[1]*orig_shape[2]*orig_shape[3]])\n",
    "    layer_drop = tf.nn.dropout(layer,keep_prob)\n",
    "    layer2 = fully_connected(layer_drop, 1000, is_training)\n",
    "    layer_drop2 = tf.nn.dropout(layer2,keep_prob)\n",
    "    logits = tf.layers.dense(layer_drop2, 2)\n",
    "\n",
    "  \n",
    "    \n",
    "#     conv_layer1 = conv_layer_2conv(layer, 64, is_training)\n",
    "#     conv_layer2 = conv_layer_2conv(conv_layer1, 128, is_training)\n",
    "#     conv_layer3 = conv_layer_3conv(conv_layer2, 256, is_training)\n",
    "#     conv_layer4 = conv_layer_3conv(conv_layer3, 512, is_training)\n",
    "#     conv_layer5 = conv_layer_3conv(conv_layer4, 512, is_training)\n",
    "\n",
    "\n",
    "     \n",
    "#     # Flatten the output from the convolutional layers\n",
    "#     orig_shape = conv_layer5.get_shape().as_list()\n",
    "#     layer = tf.reshape(conv_layer5, shape=[-1, orig_shape[1]*orig_shape[2]*orig_shape[3]])\n",
    "#     keep_prob = tf.placeholder('float')\n",
    "#     layer_drop = tf.nn.dropout(layer,keep_prob)\n",
    "#     layer2 = fully_connected(layer_drop, 4096, is_training)\n",
    "#     layer_drop2 = tf.nn.dropout(layer2,keep_prob)\n",
    "#     layer3 = fully_connected(layer_drop2, 4096, is_training)\n",
    "#     layer_drop3 = tf.nn.dropout(layer3,keep_prob)\n",
    "#     logits = tf.layers.dense(layer_drop3, 2)\n",
    "\n",
    "\n",
    "\n",
    "    # Create operations to test accuracy\n",
    "#     predict = tf.argmax(logits, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), labels), tf.float32))\n",
    "    print('Strart Inference:')\n",
    "    with tf.Session() as sess:\n",
    "        test_list = create_file_list('./data2/train/')\n",
    "        test_feeder = read_data(test_list,1,False)\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())        \n",
    "        ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "        if ckpt:\n",
    "            saver.restore(sess,ckpt)\n",
    "            print('restore from the checkpoint {0}'.format(ckpt))               \n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        try:\n",
    "            #using progress bar\n",
    "            temp_acc = 0\n",
    "            for batch_i in range(len(test_list)):\n",
    "                # train this batch\n",
    "                [test_images_batch, test_labels_batch] = next(test_feeder)\n",
    "#                 train_images_batch, train_labels_batch = sess.run([train_images, train_labels])\n",
    "                acc = sess.run(accuracy, feed_dict={inputs: test_images_batch,labels: test_labels_batch,is_training: False,keep_prob:1.0})\n",
    "                # Periodically check the validation or training loss and accuracy\n",
    "                temp_acc+=acc\n",
    "                print('Test accuracy:{} in sample:{}'.format(acc,batch_i))\n",
    "            print('Final test accuracy: {:>3.5f} in {:>1} samples'.format(temp_acc/len(test_list),len(test_list)))\n",
    "                    \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('error')\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    Inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feeder = DataIterator3(data_dir='./data2/test/')\n",
    "test_images_1, test_labels_1 = test_feeder.input_pipeline(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
